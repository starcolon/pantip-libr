#!/bin/bash

# Prepare report CSV
CSV_PATH="$PANTIPLIBR/data/report.csv"

# Dirty way to flush RabbitMQ memory
# brew services restart rabbitmq

# Delay
sleep 3

if [ ! -f "$CSV_PATH" ] 
then
	touch "$CSV_PATH"
else
	rm "$CSV_PATH"
	touch "$CSV_PATH"
fi
echo "DECOM ,  N  , #FT , TAG , % TOT ,  [0]  ,  [1]  ,  [1]" > "$CSV_PATH"

# Tokenise input
python3 core/process.py

rm data/cluster/*

rm data/hasher/*

# Quick notes:
# ------------------
# [LDA] works with chi2 best since it produces non-negative results.
#       However, it doesn't seem to decompose the principal features 
#       very efficiently. So the accuracy is not good.

# Batch trainings
python3 core/textprocess.py --decom LDA --n 200 --tagdim 16
#python3 core/requeue.py
